I"È<p>Apenas no Brasil, de acordo com a pesquisa da CNDL/SPC Brasil mostra que 59% dos internautas sofreram algum tipo de fraude financeira nos √∫ltimos 12 meses, contra 46% em 2019. Isso corresponde a um contingente 16,7 milh√µes de brasileiros. O estudo estima que o preju√≠zo decorrente de fraudes financeiras sofridas no universo dos internautas brasileiros chegou a R$ 2,7 bilh√µes nos √∫ltimos 12 meses, inclu√≠dos os gastos na busca de repara√ß√£o do problema.</p>

<p align="center">
<img src="https://www.texascitizensbank.com/wp-content/uploads/2019/04/credit-card-fraud.jpg" width="60%" /></p>

<p>Dentre essas fraudes, aquelas envolvendo cart√µes de cr√©dito s√£o de grande relev√¢ncia uma vez que n√£o sendo detectado acarretar√° em preju√≠zos consider√°veis, tanto para o consumidor quanto para a institui√ß√£o financeira.</p>

<p>Um outro fator a ser considerado √© a quantidade de falsos positivos, ou seja, aquelas vezes em que voc√™ tentou fazer uma compra e teve seu cart√£o bloqueado preventivamente - o que provavelmente gerou estresse e constrangimento.</p>

<p>Por todos esses motivos, o investimento na √°rea de detec√ß√£o de fraudes por meio de Intelig√™ncia Artificial vem crescendo a cada ano, representando uma grande oportunidade em <em>Data Science</em>.</p>

<p>Devido ao enorme volume de dados de cada cliente e cada atividade financeira, um algoritmo de <em>Machine Learning</em> pode ser utilizado para identificar com efic√°cia padr√µes suspeitos nas transa√ß√µes. Para aumentar a precis√£o das an√°lises, muitas institui√ß√µes est√£o investindo no aprimoramento de algoritmos de Intelig√™ncia Artifical. E esse √© o desafio, aprimorar cada vez mais o uso de algoritmos visando inibir ou evitar transa√ß√µes fraudulentas.</p>

<h2 id="sobre-os-dados">Sobre os Dados</h2>

<p>O <em>dataset</em> utilizado neste projeto foi retirado do <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Kaggle</a> e cont√©m opera√ß√µes financeiras realizadas em Setembro de 2013 que ocorreram no per√≠do de dois dias.</p>

<p>Podemos observar que o <em>dataset</em> √© bastante desbalanceado, uma vez que possui 492 fraudes das 284.807 transa√ß√µes, correspondendo h√° cerca de 0,17% do total.</p>

<p>Todas as <em>features</em> do <em>dataset</em> s√£o num√©ricas. Devido ao sigilo do cliente, as colunas foram renomeadas para V1, V2, ‚Ä¶, V28, e suas vari√°veis passaram por uma transforma√ß√£o PCA, que consiste em reduzir a dimensionalidade do <em>dataset</em>, ou seja, diminuir a quantidade de vari√°veis do mesmo. Para saber mais sobre PCA veja neste <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html">link</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># importar os pacotes necess√°rios
</span><span class="kn">import</span> <span class="nn">pandas</span>  <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span>   <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">scikitplot</span> <span class="k">as</span> <span class="n">skplt</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span>   <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span>    <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span>    <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">"ignore"</span><span class="p">)</span>

<span class="c1"># configurar o estilo dos gr√°ficos com o Seaborn
</span><span class="n">sns</span><span class="p">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">'dark'</span><span class="p">)</span>

<span class="c1">#importar os dados para um dataframe
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"https://www.dropbox.com/s/b44o3t3ehmnx2b7/creditcard.csv?dl=1"</span><span class="p">)</span>
</code></pre></div></div>

<p>Os dados fornecidos pelo <em>Kaggle</em> est√£o prontos para uso e n√£o precisam de qualquer altera√ß√£o. Podemos passar para a an√°lise explorat√≥ria a fim de preparar um modelo de <em>Machine Learning</em>.</p>

<h2 id="an√°lise-explorat√≥ria">An√°lise Explorat√≥ria</h2>

<p>Olhando as cinco primeiras entradas do dataframe √© poss√≠vel tirar algumas conclus√µes:</p>

<ul>
  <li>
    <p>A transforma√ß√£o PCA alterou as vari√°veis V1-v28 para num√©ricas, garantindo o anonimato dos dados.</p>
  </li>
  <li>
    <p>As duas √∫nicas exce√ß√µes foram as vari√°veis <code class="language-plaintext highlighter-rouge">Time</code> e <code class="language-plaintext highlighter-rouge">Amount</code>, contendo os segundos decorridos entre cada transa√ß√£o e a primeira transa√ß√£o no <em>dataset</em>, e o valor da transa√ß√£o, respectivamente.</p>
  </li>
  <li>
    <p>A <em>feature</em> <code class="language-plaintext highlighter-rouge">Class</code> √© a vari√°vel alvo e assume os valores:</p>

    <p>0 - para transa√ß√µes regulares</p>

    <p>1 - para transa√ß√µes fraudulentas</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div style="overflow-y: scroll; height:auto; overflow-x: scroll; width:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>0.090794</td>
      <td>-0.551600</td>
      <td>-0.617801</td>
      <td>-0.991390</td>
      <td>-0.311169</td>
      <td>1.468177</td>
      <td>-0.470401</td>
      <td>0.207971</td>
      <td>0.025791</td>
      <td>0.403993</td>
      <td>0.251412</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>149.62</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>-0.166974</td>
      <td>1.612727</td>
      <td>1.065235</td>
      <td>0.489095</td>
      <td>-0.143772</td>
      <td>0.635558</td>
      <td>0.463917</td>
      <td>-0.114805</td>
      <td>-0.183361</td>
      <td>-0.145783</td>
      <td>-0.069083</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>0.207643</td>
      <td>0.624501</td>
      <td>0.066084</td>
      <td>0.717293</td>
      <td>-0.165946</td>
      <td>2.345865</td>
      <td>-2.890083</td>
      <td>1.109969</td>
      <td>-0.121359</td>
      <td>-2.261857</td>
      <td>0.524980</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>378.66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>-0.054952</td>
      <td>-0.226487</td>
      <td>0.178228</td>
      <td>0.507757</td>
      <td>-0.287924</td>
      <td>-0.631418</td>
      <td>-1.059647</td>
      <td>-0.684093</td>
      <td>1.965775</td>
      <td>-1.232622</td>
      <td>-0.208038</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>123.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>0.753074</td>
      <td>-0.822843</td>
      <td>0.538196</td>
      <td>1.345852</td>
      <td>-1.119670</td>
      <td>0.175121</td>
      <td>-0.451449</td>
      <td>-0.237033</td>
      <td>-0.038195</td>
      <td>0.803487</td>
      <td>0.408542</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>69.99</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<p>Verificando abaixo o resumo estat√≠stico por meio do m√©todo <code class="language-plaintext highlighter-rouge">describe()</code> podemos confirmar que as vari√°veis relativas aos componentes principais (transforma√ß√£o PCA) n√£o t√™m nenhuma discrep√¢ncia aparente, bem como a vari√°vel <code class="language-plaintext highlighter-rouge">Time</code>.</p>

<p>Nota-se que a vari√°vel <code class="language-plaintext highlighter-rouge">Amount</code> tem um valor m√©dio de 88.34 e uma mediana de 22. O desvio padr√£o √© de 250.12 e temos um valor m√°ximo em uma transa√ß√£o de 25.961,16.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div style="overflow-y: scroll; height:auto; overflow-x: scroll; width:auto;">
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>284807.000000</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>284807.000000</td>
      <td>284807.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>94813.859575</td>
      <td>3.919560e-15</td>
      <td>5.688174e-16</td>
      <td>-8.769071e-15</td>
      <td>2.782312e-15</td>
      <td>-1.552563e-15</td>
      <td>2.010663e-15</td>
      <td>-1.694249e-15</td>
      <td>-1.927028e-16</td>
      <td>-3.137024e-15</td>
      <td>1.768627e-15</td>
      <td>9.170318e-16</td>
      <td>-1.810658e-15</td>
      <td>1.693438e-15</td>
      <td>1.479045e-15</td>
      <td>3.482336e-15</td>
      <td>1.392007e-15</td>
      <td>-7.528491e-16</td>
      <td>4.328772e-16</td>
      <td>9.049732e-16</td>
      <td>5.085503e-16</td>
      <td>1.537294e-16</td>
      <td>7.959909e-16</td>
      <td>5.367590e-16</td>
      <td>4.458112e-15</td>
      <td>1.453003e-15</td>
      <td>1.699104e-15</td>
      <td>-3.660161e-16</td>
      <td>-1.206049e-16</td>
      <td>88.349619</td>
      <td>0.001727</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47488.145955</td>
      <td>1.958696e+00</td>
      <td>1.651309e+00</td>
      <td>1.516255e+00</td>
      <td>1.415869e+00</td>
      <td>1.380247e+00</td>
      <td>1.332271e+00</td>
      <td>1.237094e+00</td>
      <td>1.194353e+00</td>
      <td>1.098632e+00</td>
      <td>1.088850e+00</td>
      <td>1.020713e+00</td>
      <td>9.992014e-01</td>
      <td>9.952742e-01</td>
      <td>9.585956e-01</td>
      <td>9.153160e-01</td>
      <td>8.762529e-01</td>
      <td>8.493371e-01</td>
      <td>8.381762e-01</td>
      <td>8.140405e-01</td>
      <td>7.709250e-01</td>
      <td>7.345240e-01</td>
      <td>7.257016e-01</td>
      <td>6.244603e-01</td>
      <td>6.056471e-01</td>
      <td>5.212781e-01</td>
      <td>4.822270e-01</td>
      <td>4.036325e-01</td>
      <td>3.300833e-01</td>
      <td>250.120109</td>
      <td>0.041527</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>-5.640751e+01</td>
      <td>-7.271573e+01</td>
      <td>-4.832559e+01</td>
      <td>-5.683171e+00</td>
      <td>-1.137433e+02</td>
      <td>-2.616051e+01</td>
      <td>-4.355724e+01</td>
      <td>-7.321672e+01</td>
      <td>-1.343407e+01</td>
      <td>-2.458826e+01</td>
      <td>-4.797473e+00</td>
      <td>-1.868371e+01</td>
      <td>-5.791881e+00</td>
      <td>-1.921433e+01</td>
      <td>-4.498945e+00</td>
      <td>-1.412985e+01</td>
      <td>-2.516280e+01</td>
      <td>-9.498746e+00</td>
      <td>-7.213527e+00</td>
      <td>-5.449772e+01</td>
      <td>-3.483038e+01</td>
      <td>-1.093314e+01</td>
      <td>-4.480774e+01</td>
      <td>-2.836627e+00</td>
      <td>-1.029540e+01</td>
      <td>-2.604551e+00</td>
      <td>-2.256568e+01</td>
      <td>-1.543008e+01</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>54201.500000</td>
      <td>-9.203734e-01</td>
      <td>-5.985499e-01</td>
      <td>-8.903648e-01</td>
      <td>-8.486401e-01</td>
      <td>-6.915971e-01</td>
      <td>-7.682956e-01</td>
      <td>-5.540759e-01</td>
      <td>-2.086297e-01</td>
      <td>-6.430976e-01</td>
      <td>-5.354257e-01</td>
      <td>-7.624942e-01</td>
      <td>-4.055715e-01</td>
      <td>-6.485393e-01</td>
      <td>-4.255740e-01</td>
      <td>-5.828843e-01</td>
      <td>-4.680368e-01</td>
      <td>-4.837483e-01</td>
      <td>-4.988498e-01</td>
      <td>-4.562989e-01</td>
      <td>-2.117214e-01</td>
      <td>-2.283949e-01</td>
      <td>-5.423504e-01</td>
      <td>-1.618463e-01</td>
      <td>-3.545861e-01</td>
      <td>-3.171451e-01</td>
      <td>-3.269839e-01</td>
      <td>-7.083953e-02</td>
      <td>-5.295979e-02</td>
      <td>5.600000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>84692.000000</td>
      <td>1.810880e-02</td>
      <td>6.548556e-02</td>
      <td>1.798463e-01</td>
      <td>-1.984653e-02</td>
      <td>-5.433583e-02</td>
      <td>-2.741871e-01</td>
      <td>4.010308e-02</td>
      <td>2.235804e-02</td>
      <td>-5.142873e-02</td>
      <td>-9.291738e-02</td>
      <td>-3.275735e-02</td>
      <td>1.400326e-01</td>
      <td>-1.356806e-02</td>
      <td>5.060132e-02</td>
      <td>4.807155e-02</td>
      <td>6.641332e-02</td>
      <td>-6.567575e-02</td>
      <td>-3.636312e-03</td>
      <td>3.734823e-03</td>
      <td>-6.248109e-02</td>
      <td>-2.945017e-02</td>
      <td>6.781943e-03</td>
      <td>-1.119293e-02</td>
      <td>4.097606e-02</td>
      <td>1.659350e-02</td>
      <td>-5.213911e-02</td>
      <td>1.342146e-03</td>
      <td>1.124383e-02</td>
      <td>22.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>139320.500000</td>
      <td>1.315642e+00</td>
      <td>8.037239e-01</td>
      <td>1.027196e+00</td>
      <td>7.433413e-01</td>
      <td>6.119264e-01</td>
      <td>3.985649e-01</td>
      <td>5.704361e-01</td>
      <td>3.273459e-01</td>
      <td>5.971390e-01</td>
      <td>4.539234e-01</td>
      <td>7.395934e-01</td>
      <td>6.182380e-01</td>
      <td>6.625050e-01</td>
      <td>4.931498e-01</td>
      <td>6.488208e-01</td>
      <td>5.232963e-01</td>
      <td>3.996750e-01</td>
      <td>5.008067e-01</td>
      <td>4.589494e-01</td>
      <td>1.330408e-01</td>
      <td>1.863772e-01</td>
      <td>5.285536e-01</td>
      <td>1.476421e-01</td>
      <td>4.395266e-01</td>
      <td>3.507156e-01</td>
      <td>2.409522e-01</td>
      <td>9.104512e-02</td>
      <td>7.827995e-02</td>
      <td>77.165000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172792.000000</td>
      <td>2.454930e+00</td>
      <td>2.205773e+01</td>
      <td>9.382558e+00</td>
      <td>1.687534e+01</td>
      <td>3.480167e+01</td>
      <td>7.330163e+01</td>
      <td>1.205895e+02</td>
      <td>2.000721e+01</td>
      <td>1.559499e+01</td>
      <td>2.374514e+01</td>
      <td>1.201891e+01</td>
      <td>7.848392e+00</td>
      <td>7.126883e+00</td>
      <td>1.052677e+01</td>
      <td>8.877742e+00</td>
      <td>1.731511e+01</td>
      <td>9.253526e+00</td>
      <td>5.041069e+00</td>
      <td>5.591971e+00</td>
      <td>3.942090e+01</td>
      <td>2.720284e+01</td>
      <td>1.050309e+01</td>
      <td>2.252841e+01</td>
      <td>4.584549e+00</td>
      <td>7.519589e+00</td>
      <td>3.517346e+00</td>
      <td>3.161220e+01</td>
      <td>3.384781e+01</td>
      <td>25691.160000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>Quanto √† qualidade do <em>dataset</em>, este n√£o apresentou nenhum valor ausente ou que demandasse uma etapa de limpeza, ent√£o estamos prontos para seguir em frente.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># verificar se h√° valores nulos
</span><span class="n">df</span><span class="p">.</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">().</span><span class="nb">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0
</code></pre></div></div>

<p>Como foi informado na descri√ß√£o dos dados, as entradas relativas √† transa√ß√µes fraudulentas correspondam a 0,17% do total. Vamos verificar essa discrep√¢ncia no gr√°fico abaixo.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plotar gr√°fico de barras para as Classes
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Distribui√ß√£o das Classes'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_11_0.png" alt="png" /></p>

<p>Agora vamos verificar a distribui√ß√£o das duas classes ao longo do tempo. No entanto, n√£o foi identificada nenhum informa√ß√£o a partir das distribui√ß√µes de frequ√™ncia abaixo.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">Time</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">Class</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Transa√ß√µes regulares'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Tempo (segundos)'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Quantidade'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">Time</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">Class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Transa√ß√µes fraudulentas'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Tempo (segundos)'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Quantidade'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_13_0.png" alt="png" /></p>

<p>Embora o n√∫mero de transa√ß√µes fraudulentas seja significativamente menor do que o n√∫mero de transa√ß√µes regulares, podemos ver um comportamento distinto, especialmente em torno da marca de tempo 100.000.</p>

<p>Observe que o n√∫mero de transa√ß√µes regulares cai drasticamente em torno da marca de 90.000 segundos, para aumentar novamente em torno da marca de 110.000 segundos. N√£o seria absurdo supor que esse per√≠odo seja durante a noite, quando as pessoas naturalmente realizam menos compras do que durante o dia. Por outro lado, um grande n√∫mero de transa√ß√µes fraudulentas ocorreram em torno da marca de 100.000, o que poderia confirmar a premissa anterior, considerando que os fraudadores devem preferir cometer fraudes tarde da noite, supondo que haveria menos vigil√¢ncia.</p>

<p>Isso √© apenas uma hip√≥tese. Vamos esperar para ver como nosso modelo de <em>Machine Learning</em> interpretar√° esses n√∫meros.</p>

<p>Podemos fazer a mesma an√°lise utilizando a vari√°vel <code class="language-plaintext highlighter-rouge">Amount</code> de cada transa√ß√£o.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">Amount</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">Class</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Transa√ß√µes regulares'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Valor'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Quantidade'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">Amount</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">Class</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Transa√ß√µes fraudulentas'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'Valor'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Quantidade'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_16_0.png" alt="png" /></p>

<p>Quanto ao valor das transa√ß√µes, aparentemente n√£o h√° um <em>insight</em> significativo que possamos obter delas. A maioria das transa√ß√µes, regulares e fraudulentas, eram de valores ‚Äúpequenos‚Äù. Como vimos anteriormente, a maioria das transa√ß√µes s√£o de menos de 100.00.</p>

<p>No entanto, podemos realizar uma inspe√ß√£o mais profunda com um gr√°fico de <em>boxplot</em>.</p>

<p>Usamos o <em>boxplot</em> para ver se h√° alguma diferen√ßa no padr√£o transa√ß√µes em rela√ß√£o √† dimens√£o <code class="language-plaintext highlighter-rouge">Amount</code>. De uma maneira geral, percebe-se uma distribui√ß√£o diferente para as duas classes, o que provavelmente ir√° contribuir para o treinamento do modelo de <em>Machine Learning</em>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">Class</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">Amount</span><span class="p">,</span> <span class="n">showmeans</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">((</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">400</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s">'Normal'</span><span class="p">,</span> <span class="s">'Fraude'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_19_0.png" alt="png" /></p>

<p>Vamos plotar um gr√°fico de matriz de correla√ß√£o para determinar a correla√ß√£o entre as vari√°veis.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#cria uma vari√°vel que recebe a fun√ß√£o corr(), que calcula a correla√ß√£o entre as colunas.
</span><span class="n">corr</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#plota um gr√°fico de correla√ß√£o utilizando a vari√°vel criada com a fun√ß√£o corr()
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="n">linewidths</span><span class="o">=</span><span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"coolwarm"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_22_0.png" alt="png" /></p>

<p>N√£o foi observado nenhuma correla√ß√£o forte entre as vari√°veis.</p>

<h2 id="preparando-os-dados">Preparando os dados</h2>

<p><strong>Padronizar as vari√°veis <code class="language-plaintext highlighter-rouge">Time</code> e <code class="language-plaintext highlighter-rouge">Amount</code></strong></p>

<p>Este √© um passo essencial para que os dados sejam interpretados de forma correta pelo algoritmo de <em>Machine Learning</em>. Uma vez que a coluna <code class="language-plaintext highlighter-rouge">Amount</code> possui <em>outliers</em>, ser√° usada a padroniza√ß√£o por meio da classe <code class="language-plaintext highlighter-rouge">StandardScaler</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#criar uma c√≥pia do dataframe
</span><span class="n">df_clean</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1">#padronizar as colunas Time e Amount
</span><span class="n">std_scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">df_clean</span><span class="p">[</span><span class="s">'std_amount'</span><span class="p">]</span> <span class="o">=</span> <span class="n">std_scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_clean</span><span class="p">[</span><span class="s">'Amount'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">df_clean</span><span class="p">[</span><span class="s">'std_time'</span><span class="p">]</span> <span class="o">=</span> <span class="n">std_scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_clean</span><span class="p">[</span><span class="s">'Time'</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">df_clean</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Time'</span><span class="p">,</span> <span class="s">'Amount'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>Ap√≥s a padroniza√ß√£o vamos verificar como ficou o <em>dataframe</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_clean</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div style="overflow-y: scroll; height:auto; overflow-x: scroll; width:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Class</th>
      <th>std_amount</th>
      <th>std_time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>0.090794</td>
      <td>-0.551600</td>
      <td>-0.617801</td>
      <td>-0.991390</td>
      <td>-0.311169</td>
      <td>1.468177</td>
      <td>-0.470401</td>
      <td>0.207971</td>
      <td>0.025791</td>
      <td>0.403993</td>
      <td>0.251412</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>0</td>
      <td>0.244964</td>
      <td>-1.996583</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>-0.166974</td>
      <td>1.612727</td>
      <td>1.065235</td>
      <td>0.489095</td>
      <td>-0.143772</td>
      <td>0.635558</td>
      <td>0.463917</td>
      <td>-0.114805</td>
      <td>-0.183361</td>
      <td>-0.145783</td>
      <td>-0.069083</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>0</td>
      <td>-0.342475</td>
      <td>-1.996583</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>0.207643</td>
      <td>0.624501</td>
      <td>0.066084</td>
      <td>0.717293</td>
      <td>-0.165946</td>
      <td>2.345865</td>
      <td>-2.890083</td>
      <td>1.109969</td>
      <td>-0.121359</td>
      <td>-2.261857</td>
      <td>0.524980</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>0</td>
      <td>1.160686</td>
      <td>-1.996562</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>-0.054952</td>
      <td>-0.226487</td>
      <td>0.178228</td>
      <td>0.507757</td>
      <td>-0.287924</td>
      <td>-0.631418</td>
      <td>-1.059647</td>
      <td>-0.684093</td>
      <td>1.965775</td>
      <td>-1.232622</td>
      <td>-0.208038</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>0</td>
      <td>0.140534</td>
      <td>-1.996562</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>0.753074</td>
      <td>-0.822843</td>
      <td>0.538196</td>
      <td>1.345852</td>
      <td>-1.119670</td>
      <td>0.175121</td>
      <td>-0.451449</td>
      <td>-0.237033</td>
      <td>-0.038195</td>
      <td>0.803487</td>
      <td>0.408542</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>0</td>
      <td>-0.073403</td>
      <td>-1.996541</td>
    </tr>
  </tbody>
</table>
</div>

<p><strong>Dividir entre conjuntos de treino e teste</strong></p>

<p>Depois de padronizar as <em>features</em> <code class="language-plaintext highlighter-rouge">Time</code> e <code class="language-plaintext highlighter-rouge">Amount</code>, vamos dividir o <em>dataset</em> em treino e teste. Caso contr√°rio, n√£o teremos par√¢metros para conferir se no momento do balanceamento dos dados foi adequado. Usaremos a divis√£o padr√£o para o conjunto de teste de 25%.
Para garantir que os conjuntos de treino e teste tenham a mesma quantidade de classes proporcionalmente, passamos o par√¢metro <code class="language-plaintext highlighter-rouge">stratify=True</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#separar target vector da feature matrix
</span><span class="n">X</span> <span class="o">=</span> <span class="n">df_clean</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_clean</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span>

<span class="c1">#dividir entre treino e teste
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Balanceamento dos dados</strong></p>

<p>Como mencionado antes, o dataset est√° bastante desbalanceado. Como existe uma grande diferen√ßa na distribui√ß√£o das classes(284.315 classe 0 e 492 classe 1) o conjunto de treino pode ser tendencioso e influenciar o algoritmo de <em>Machine Learning</em> a exibir resultados desbalanceados, por exemplo, ignorando a classe com menos entradas.</p>

<p>Para resolver esse problema, vamos usar a biblioteca <code class="language-plaintext highlighter-rouge">imblearn</code> e aplicar t√©cnicas de balanceamento de dados. Existem duas abordagens principais para isso, sendo:</p>

<ul>
  <li><em>Random Oversampling</em>: Duplica aleatoriamente observa√ß√µes da classe de menor ocorr√™ncia utilizando <em>RandomOverSampler()</em></li>
  <li><em>Random Undersampling</em>: Exclui aleatoriamente observa√ß√µes da classe de maior ocorr√™ncia utilizando <em>RandomUnderSampler()</em></li>
</ul>

<p>Utilizaremos o <em>Random Undersamping</em>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#usar t√©cnica de undersampling
</span><span class="n">rus</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">()</span>
<span class="n">X_rus</span><span class="p">,</span> <span class="n">y_rus</span> <span class="o">=</span> <span class="n">rus</span><span class="p">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<p>Vamos verificar como ficou os dados ap√≥s o balanceamento:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y_rus</span><span class="p">).</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">y_rus</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1    369
0    369
dtype: int64
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_37_1.png" alt="png" /></p>

<p>N√≥s balanceamos os dados, com 369 entradas para cada classe. Vamos verificar a matriz de correla√ß√£o novamente para ver se podemos determinar alguma correla√ß√£o.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#plotar matriz de corre√ß√£o
</span><span class="n">corr</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">corr_rus</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_rus</span><span class="p">).</span><span class="n">corr</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">19</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Matriz de Correla√ß√£o'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr_rus</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
            <span class="n">linewidths</span><span class="o">=</span><span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">"coolwarm"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Balanceado'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_39_0.png" alt="png" /></p>

<p>Observe como anteriormente, sem o balanceamento de dados, a matriz de correla√ß√£o n√£o trazia nenhuma informa√ß√£o relevante. Entretanto, ela traz muito mais informa√ß√µes ap√≥s um correto balanceamento.</p>

<h2 id="modelo-de-machine-learning">Modelo de Machine Learning</h2>

<p>Com todos os dados preparados e ap√≥s uma an√°lise explorat√≥ria completa ,vamos utilizar dois dos principais m√©todos de classifica√ß√£o de <em>Machine Learning</em>:</p>
<ul>
  <li>Regress√£o Log√≠stica</li>
  <li><em>Decision Tree</em></li>
</ul>

<p>Ap√≥s instanciar o modelo, o mesmo ser√° treinado em cima dos dados em <code class="language-plaintext highlighter-rouge">X_rus</code> e <code class="language-plaintext highlighter-rouge">y_rus</code>. Na sequ√™ncia, ser√£o realizadas as previs√µes sobre os dados de teste.</p>

<h3 id="regress√£o-log√≠stica">Regress√£o Log√≠stica</h3>

<p>O modelo de Regress√£o Log√≠stica √© usado para determinar as chances de uma determinada classe ou evento existir. No nosso caso, vai estabelecer a probabilidade de uma transa√ß√£o pertencer a classe 0 ou 1, ou seja, regular ou fraudulenta.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#instanciar e treinar o modelo de Regress√£o Log√≠stica
</span><span class="n">model_lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model_lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_rus</span><span class="p">,</span> <span class="n">y_rus</span><span class="p">)</span>

<span class="n">y_pred_lr</span> <span class="o">=</span> <span class="n">model_lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<p>Vamos avaliar a acur√°cia do modelo usando o <code class="language-plaintext highlighter-rouge">classification_report</code>, <code class="language-plaintext highlighter-rouge">roc_auc_score</code> e <code class="language-plaintext highlighter-rouge">confusion_matrix</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># exibir o relat√≥rio de classifica√ß√£o
</span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr</span><span class="p">))</span>

<span class="c1"># imprimir o score AUC
</span><span class="k">print</span><span class="p">(</span><span class="s">"ROC AUC score: {:.2f}</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr</span><span class="p">)))</span>


<span class="c1"># plotar a matriz de confus√£o
</span><span class="n">skplt</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_lr</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       1.00      0.97      0.98     71079
           1       0.05      0.89      0.09       123

    accuracy                           0.97     71202
   macro avg       0.52      0.93      0.54     71202
weighted avg       1.00      0.97      0.98     71202

ROC AUC score: 0.93
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_45_1.png" alt="png" /></p>

<p>O modelo teve uma acur√°cia de 97% e uma AUC de 93%, o que significa que o nosso modelo de Regress√£o Log√≠stica teve um desempenho muito bom.</p>

<p>A partir da matriz de confus√£o podemos concluir que 97% das transa√ß√µes regulares foram corretamente classificadas como regulares(Verdadeiro Negativo), e 89% das transa√ß√µes fraudulentas foram corretamente classificadas como fraudes(Verdadeiro Positivo).</p>

<h3 id="decision-tree">Decision Tree</h3>

<p>N√≥s vimos que o modelo de Regress√£o Log√≠stica teve um bom desempenho. Agora vamos ver como o modelo de <em>Decision Tree</em> se sai.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#instanciar e treinar o modelo de Decision Tree
</span><span class="n">model_tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s">"entropy"</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model_tree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_rus</span><span class="p">,</span> <span class="n">y_rus</span><span class="p">)</span>

<span class="n">y_pred_tree</span> <span class="o">=</span> <span class="n">model_tree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># classification report
</span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_tree</span><span class="p">))</span>

<span class="c1"># ROC AUC score
</span><span class="k">print</span><span class="p">(</span><span class="s">"ROC AUC Score: {:.2f}</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_tree</span><span class="p">)))</span>

<span class="c1"># plotar a matriz de confus√£o
</span><span class="n">skplt</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_tree</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       1.00      0.96      0.98     71079
           1       0.03      0.87      0.06       123

    accuracy                           0.96     71202
   macro avg       0.52      0.91      0.52     71202
weighted avg       1.00      0.96      0.98     71202

ROC AUC Score: 0.91
</code></pre></div></div>

<p><img src="\img\posts\fraud-detection\output_49_1.png" alt="png" /></p>

<p>O modelo de <em>Decision Tree</em> obteve um desempenho com uma acur√°cia de 96% e <em>AUC score</em> de 91%. Os verdadeiros positivos e verdadeiros negativos foram bem previstos, com 96% e 87% respectivamente.</p>

<h2 id="conclus√£o">Conclus√£o</h2>

<p>Ambos os modelos, de Regress√£o Log√≠stica e <em>Decision Tree</em> desempenharam muito bem na classifica√ß√£o das atividades de cart√£o de cr√©dito, com uma acur√°cia, AUC e precis√£o acima de 90%.</p>

<p>Embora tenham produzido resultados semelhantes, o modelo de Regress√£o Log√≠stica exibiu um resultado melhor, com uma acur√°cia de 97%.</p>

<p>√â importante tamb√©m ressaltar o pr√©-processamento e o balanceamento dos dados. Lembre-se de como a matriz de correla√ß√£o teve um desempenho melhor ap√≥s o balanceamento dos mesmos.</p>

<p>Obviamente, apesar do bom resultado final, h√° espa√ßo para testar o desempenho com outros algoritmos de classifica√ß√£o, al√©m de otimizar seus par√¢metros.</p>

<p>Os algoritmos de <em>Machine Learning</em> para detectar fraudes de cart√£o de cr√©dito s√£o altamente eficientes, mas ainda existem falhas a serem corrigidas. Um dos maiores problemas √© a ocorr√™ncia de Falsos Positivos, ou seja, quando o algoritmo detecta incorretamente uma fraude.</p>
:ET